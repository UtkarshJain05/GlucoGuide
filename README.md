# ğŸ©ºGlucoGuide
## ğŸ›‘ CHECKPOINT 0 â€” PROJECT FOUNDATION

### ğŸ¯ Objective
Establish a clean and reliable development foundation before starting any implementation.

### âœ… What Was Completed
- Created a dedicated project directory
- Initialized a Python virtual environment
- Configured Visual Studio Code for development
- Set up PowerShell as the primary terminal

This checkpoint ensures the project starts with a professional and reproducible setup, aligned with real-world machine learning and AI workflows.

## ğŸ›‘ CHECKPOINT 1 â€” PROJECT FOLDER STRUCTURE

### ğŸ¯ Objective
Design a clean, scalable, and professional folder structure for the project.

### âœ… What Was Completed
- Created a standardized directory layout
- Separated data, source code, notebooks, and tests
- Established a clear location for storing the WHO diabetes PDF
- Ensured the project structure supports future scalability

### ğŸ“ Folder Structure
```text
GlucoGuide/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ src/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ tests/
â””â”€â”€ README.md
```

## ğŸ›‘ CHECKPOINT 2 â€” DATA INGESTION SETUP (FOUNDATION)

### ğŸ¯ Objective
Prepare the project for reliable document ingestion without implementing processing logic.

### âœ… What Was Completed
- Added the WHO diabetes PDF to the appropriate data directory
- Organized raw documents for future ingestion pipelines
- Configured `.gitignore` to protect unnecessary and sensitive files
- Verified that document images do not affect ingestion workflows

### ğŸ“ Data Layout
```text
data/
â””â”€â”€ raw/
    â””â”€â”€ who_diabetes_guidelines.pdf
```

## ğŸ›‘ CHECKPOINT 3 â€” PYTHON FOUNDATION (CORE FILES)

### ğŸ¯ Objective
Establish the core Python entry points and configuration files required to start the application.

### âœ… What Was Completed
- Created essential Python source files
- Defined a clear execution entry point
- Added a centralized configuration module
- Ensured the project is ready for controlled expansion

### ğŸ“ Core Source Structure
```text
src/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ config.py
â””â”€â”€ main.py
```

## ğŸ›‘ CHECKPOINT 4 â€” DEPENDENCY SETUP

### ğŸ¯ Objective
Configure and install all required project dependencies in a controlled and reproducible environment.

### âœ… What Was Completed
- Created a `requirements.txt` file
- Defined all core Python dependencies explicitly
- Installed libraries inside an isolated virtual environment
- Verified successful installation and compatibility

### ğŸ“¦ Dependency Management
All dependencies are pinned and managed using `requirements.txt` to ensure consistent behavior across environments.

```text
requirements.txt
```
## ğŸ›‘ CHECKPOINT 5 â€” DOCUMENT LOADING (FIRST RAG STEP)

### ğŸ¯ Objective
Load and validate the WHO diabetes PDF as the first operational step in the RAG pipeline.

### âœ… What Was Completed
- Loaded the WHO diabetes PDF using LangChain document loaders
- Converted the PDF into structured `Document` objects
- Verified successful page extraction
- Printed sample text content to confirm correct parsing
- Confirmed that embedded images do not interfere with text extraction

### ğŸ“„ Document Processing
At this stage, the project focuses exclusively on **document ingestion and validation**, ensuring reliable text extraction before downstream processing.

This checkpoint marks the transition from project setup to active RAG pipeline development while maintaining a controlled, incremental approach.

## ğŸ›‘ CHECKPOINT 6 â€” TEXT CHUNKING (CORE RAG CONCEPT)

### ğŸ¯ Objective
Transform raw document text into structured, overlapping chunks suitable for downstream retrieval workflows.

### âœ… What Was Completed
- Implemented text chunking using a recursive splitting strategy
- Defined optimal chunk size and overlap for semantic continuity
- Converted extracted PDF text into clean, structured chunks
- Inspected sample chunks to validate content integrity and boundaries

### ğŸ§© Text Preparation
Chunking ensures that long documents are broken into manageable units while preserving contextual meaning, enabling accurate and efficient retrieval in later stages.

This checkpoint completes the document preprocessing foundation required for embedding and vector storage integration.

## ğŸ›‘ CHECKPOINT 7 â€” LOCAL EMBEDDINGS WITH MINI-LM (WINDOWS-STABLE)

### ğŸ¯ Objective
Enable semantic retrieval by generating document embeddings locally using a Windows-compatible configuration.

### âœ… What Was Completed
- Implemented local embedding generation using the MiniLM model from Hugging Face
- Configured the embedding pipeline to run fully offline and CPU-only
- Applied strict dependency version pinning to ensure Windows compatibility
- Stored vector embeddings in a Chroma vector database
- Enabled semantic similarity search over document chunks

### âš™ï¸ Platform-Specific Configuration
To ensure stable execution on Windows systems, the embedding stack was configured with carefully selected versions:

- CPU-only PyTorch stack (no CUDA dependency)
- Compatible `sentence-transformers`, `transformers`, and `tokenizers` versions
- Avoided known Windows-breaking updates in newer releases

This configuration prevents common runtime and installation issues observed with MiniLM on Windows environments.

### ğŸ§  Embedding & Retrieval Layer
This checkpoint introduces the core retrieval mechanism of the RAG pipeline, allowing the system to identify and retrieve contextually relevant document chunks based on user queries.

With embeddings and vector storage in place, the project now supports reliable semantic search over the WHO diabetes documentation.

### ğŸ”’ Dependency Installation Safety
All dependencies were installed using the following command to prevent any automatic or silent dependency upgrades by `pip`:

```bash
pip install -r requirements.txt --no-deps
```

## ğŸ›‘ CHECKPOINT 8 â€” RAG WITH OPENROUTER LLAMA-3.1

### ğŸ¯ Objective
Enable end-to-end medical question answering by integrating Retrieval-Augmented Generation (RAG) with an API-based large language model.

### âœ… What Was Completed
- Implemented a user-facing natural language question interface
- Retrieved the most relevant document chunks using MiniLM embeddings and Chroma DB
- Integrated OpenRouter as the LLM gateway
- Used LLaMA-3.1 via OpenRouter for response generation
- Generated clear, context-grounded medical answers
- Included page-level source citations for transparency
- Appended a medical safety disclaimer to all responses

### ğŸ” LLM Architecture Update
This checkpoint replaces the local language model with an API-based LLM accessed through OpenRouter.  
All retrieval, chunking, embedding, and citation logic remains unchanged.

### ğŸ§  RAG Execution Flow
1. User submits a medical question  
2. Relevant document chunks are retrieved via MiniLM + Chroma DB  
3. Retrieved context is injected into an OpenRouter prompt  
4. LLaMA-3.1 generates a grounded answer  
5. Source citations and medical disclaimer are appended  

This checkpoint completes the full Retrieval-Augmented Generation pipeline, transforming **GlucoGuide** into a functional, scalable, and production-ready medical QA system.
